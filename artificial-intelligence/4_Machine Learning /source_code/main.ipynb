{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Product Performance Analysis\n",
        "## Machine Learning Assignment\n",
        "\n",
        "This notebook presents a comprehensive analysis of supermarket product sales data using:\n",
        "- **K-means Clustering** (implemented from scratch)\n",
        "- **Regression Models** (Linear and Polynomial)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Overview and Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add source code to path\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "\n",
        "from preprocessing import *\n",
        "from kmeans import *\n",
        "from regression import *\n",
        "\n",
        "# Set style for better visualizations\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except OSError:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except OSError:\n",
        "        plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Load data\n",
        "df = load_data('../data/product_sales.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic dataset statistics\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Total products: {len(df)}\")\n",
        "print(f\"\\nFeatures:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "### 2.1 Missing Value Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze missing values\n",
        "missing_info = analyze_missing_values(df)\n",
        "print(\"Missing Value Analysis:\")\n",
        "print(f\"Total missing values: {missing_info['total_missing']}\")\n",
        "print(f\"\\nMissing values by column:\")\n",
        "print(missing_info['missing_by_column'])\n",
        "print(f\"\\nMissing percentage by column:\")\n",
        "print(missing_info['missing_percentage'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Handle Missing Values\n",
        "\n",
        "**Strategy:**\n",
        "- For missing product names: Fill with category-based placeholder\n",
        "- For missing numerical values: Use mean imputation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "df_cleaned = handle_missing_values(df, strategy='mean')\n",
        "print(f\"After handling missing values:\")\n",
        "print(f\"Remaining missing values: {df_cleaned.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Outlier Detection and Normalization\n",
        "\n",
        "**Outlier Strategy:** Cap outliers at IQR bounds (preserves data while handling extremes)\n",
        "\n",
        "**Normalization:** Standardization (Z-score) - required for K-means clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect and handle outliers\n",
        "numerical_cols = ['price', 'cost', 'units_sold', 'promotion_frequency', 'shelf_level', 'profit']\n",
        "outliers_iqr = detect_outliers_iqr(df_cleaned, numerical_cols)\n",
        "df_processed = handle_outliers(df_cleaned, outliers_iqr, method='cap')\n",
        "\n",
        "# Normalize features for clustering\n",
        "clustering_features = ['price', 'cost', 'units_sold', 'promotion_frequency', 'shelf_level']\n",
        "df_normalized, scaler = normalize_features(df_processed, clustering_features, method='standardize')\n",
        "\n",
        "print(\"Preprocessing complete!\")\n",
        "print(f\"Processed shape: {df_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. K-means Clustering Analysis\n",
        "\n",
        "### 3.1 Elbow Method for Optimal K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for clustering\n",
        "X_cluster = df_normalized[clustering_features].values\n",
        "\n",
        "# Run elbow method\n",
        "k_range = range(2, 9)\n",
        "elbow_results = elbow_method(X_cluster, k_range, max_iters=100, random_state=42)\n",
        "k_values = elbow_results['k_values']\n",
        "wcss_values = elbow_results['wcss_values']\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, wcss_values, marker='o', linewidth=2, markersize=8)\n",
        "plt.xlabel('Number of Clusters (k)', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)', fontsize=12, fontweight='bold')\n",
        "plt.title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(k_values)\n",
        "\n",
        "# Determine optimal k (find largest decrease)\n",
        "decreases = [wcss_values[i] - wcss_values[i+1] for i in range(len(wcss_values)-1)]\n",
        "optimal_k = k_values[decreases.index(max(decreases)) + 1] if len(decreases) > 0 else 4\n",
        "elbow_idx = k_values.index(optimal_k)\n",
        "plt.plot(optimal_k, wcss_values[elbow_idx], 'ro', markersize=12, label=f'Optimal k={optimal_k}')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Optimal k: {optimal_k}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 K-means Clustering and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run K-means with optimal k\n",
        "labels, centroids, final_wcss, iterations = kmeans(X_cluster, optimal_k, \n",
        "                                                    max_iters=100, \n",
        "                                                    init_method='kmeans++',\n",
        "                                                    random_state=42)\n",
        "df_processed['cluster'] = labels\n",
        "\n",
        "# Calculate cluster statistics\n",
        "cluster_stats = []\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = df_processed[df_processed['cluster'] == cluster_id]\n",
        "    stats = {\n",
        "        'Cluster': cluster_id,\n",
        "        'Count': len(cluster_data),\n",
        "        'Avg Price': cluster_data['price'].mean(),\n",
        "        'Avg Units Sold': cluster_data['units_sold'].mean(),\n",
        "        'Avg Profit': cluster_data['profit'].mean(),\n",
        "        'Avg Promotion Frequency': cluster_data['promotion_frequency'].mean()\n",
        "    }\n",
        "    cluster_stats.append(stats)\n",
        "\n",
        "cluster_df = pd.DataFrame(cluster_stats)\n",
        "print(\"Cluster Statistics:\")\n",
        "print(cluster_df.round(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Cluster Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cluster scatter plot\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8', '#F7DC6F', '#BB8FCE']\n",
        "\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = df_processed[df_processed['cluster'] == cluster_id]\n",
        "    ax.scatter(cluster_data['price'], cluster_data['units_sold'], \n",
        "              c=colors[cluster_id], label=f\"Cluster {cluster_id}\",\n",
        "              s=100, alpha=0.6, edgecolors='black', linewidth=1)\n",
        "\n",
        "# Mark centroids\n",
        "centroids_original = scaler.inverse_transform(centroids)\n",
        "centroid_prices = centroids_original[:, clustering_features.index('price')]\n",
        "centroid_units = centroids_original[:, clustering_features.index('units_sold')]\n",
        "ax.scatter(centroid_prices, centroid_units, c='red', marker='X', s=300, \n",
        "          label='Centroids', edgecolors='black', linewidth=2, zorder=10)\n",
        "\n",
        "ax.set_xlabel('Price ($)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Units Sold', fontsize=12, fontweight='bold')\n",
        "ax.set_title('K-means Clustering Results: Price vs Units Sold', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare data\n",
        "feature_cols = ['price', 'cost', 'units_sold', 'promotion_frequency', 'shelf_level']\n",
        "target_col = 'profit'\n",
        "X_reg, y_reg = prepare_regression_data(df_processed, feature_cols, target_col)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train models\n",
        "linear_model = train_linear_regression(X_train, y_train)\n",
        "linear_pred_test = linear_model.predict(X_test)\n",
        "\n",
        "poly_model, poly_transformer = train_polynomial_regression(X_train, y_train, degree=2)\n",
        "poly_pred_test = poly_model.predict(poly_transformer.transform(X_test))\n",
        "\n",
        "# Evaluate\n",
        "linear_metrics = evaluate_model(y_test, linear_pred_test)\n",
        "poly_metrics = evaluate_model(y_test, poly_pred_test)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Linear Regression - R²: {linear_metrics['R2']:.3f}, RMSE: {linear_metrics['RMSE']:.2f}\")\n",
        "print(f\"Polynomial Regression - R²: {poly_metrics['R2']:.3f}, RMSE: {poly_metrics['RMSE']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Regression Visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Key Findings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"KEY FINDINGS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. DATA PREPROCESSING:\")\n",
        "print(f\"   - Handled missing values using appropriate strategies\")\n",
        "print(f\"   - Detected and capped outliers using IQR method\")\n",
        "print(f\"   - Standardized features for K-means clustering\")\n",
        "\n",
        "print(\"\\n2. CLUSTERING ANALYSIS:\")\n",
        "print(f\"   - Optimal number of clusters: {optimal_k}\")\n",
        "print(f\"   - Identified {optimal_k} distinct product groups\")\n",
        "for idx, row in cluster_df.iterrows():\n",
        "    print(f\"     • Cluster {int(row['Cluster'])}: {int(row['Count'])} products\")\n",
        "\n",
        "print(\"\\n3. REGRESSION ANALYSIS:\")\n",
        "best_model = \"Linear Regression\" if linear_metrics['RMSE'] < poly_metrics['RMSE'] else \"Polynomial Regression\"\n",
        "best_metrics = linear_metrics if best_model == \"Linear Regression\" else poly_metrics\n",
        "print(f\"   - Best model: {best_model}\")\n",
        "print(f\"   - Test R²: {best_metrics['R2']:.3f}\")\n",
        "print(f\"   - Test RMSE: ${best_metrics['RMSE']:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Analysis complete!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actual vs Predicted plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Linear Regression\n",
        "axes[0].scatter(y_test, linear_pred_test, alpha=0.6, s=80, edgecolors='black', linewidth=0.5)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "            'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual Profit ($)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Predicted Profit ($)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title(f'Linear Regression\\nR² = {linear_metrics[\"R2\"]:.3f}, RMSE = {linear_metrics[\"RMSE\"]:.2f}', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Polynomial Regression\n",
        "axes[1].scatter(y_test, poly_pred_test, alpha=0.6, s=80, edgecolors='black', linewidth=0.5, color='green')\n",
        "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "            'r--', lw=2, label='Perfect Prediction')\n",
        "axes[1].set_xlabel('Actual Profit ($)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Predicted Profit ($)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title(f'Polynomial Regression\\nR² = {poly_metrics[\"R2\"]:.3f}, RMSE = {poly_metrics[\"RMSE\"]:.2f}', \n",
        "                 fontsize=12, fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Actual vs Predicted Profit Comparison', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
